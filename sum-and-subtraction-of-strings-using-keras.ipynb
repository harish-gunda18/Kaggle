{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_model_weights.h5']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import itertools\n",
    "ops = { \"+\": operator.add, \"-\": operator.sub }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_equations(allowed_operators, dataset_size, min_value, max_value):\n",
    "    \"\"\"Generates pairs of equations and solutions to them.\n",
    "    \n",
    "       Each equation has a form of two integers with an operator in between.\n",
    "       Each solution is an integer with the result of the operaion.\n",
    "    \n",
    "        allowed_operators: list of strings, allowed operators.\n",
    "        dataset_size: an integer, number of equations to be generated.\n",
    "        min_value: an integer, min value of each operand.\n",
    "        max_value: an integer, max value of each operand.\n",
    "\n",
    "        result: a list of tuples of strings (equation, solution).\n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    number_permutations = itertools.permutations(range(min_value, max_value + 1), 2)\n",
    "\n",
    "        # Shuffle if required. The downside is we need to convert to list first\n",
    "    \n",
    "    number_permutations = list(number_permutations)\n",
    "    random.shuffle(number_permutations)\n",
    "\n",
    "    # If a max_count is given, use itertools to only look at that many items\n",
    "    if dataset_size is not None:\n",
    "        number_permutations = itertools.islice(number_permutations, dataset_size)\n",
    "\n",
    "    # Build an equation string for each and yield to caller\n",
    "    c=0\n",
    "    for x, y in number_permutations:\n",
    "        if c%2==0:\n",
    "            a='{}+{}'.format(x, y)\n",
    "        else:\n",
    "            a='{}-{}'.format(x, y)\n",
    "        b=eval(a)\n",
    "        a=a+'$'\n",
    "        b=str(b)+'$'\n",
    "        sample.append((a,b))\n",
    "        c+=1\n",
    "        ######################################\n",
    "        ######### YOUR CODE HERE #############\n",
    "        ######################################\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_operators = ['+', '-']\n",
    "dataset_size = 40000\n",
    "data = generate_equations(allowed_operators, dataset_size, min_value=0, max_value=999)\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'+': 0, '-': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '0': 11, '<pad>': 12, '$': 13}\n"
     ]
    }
   ],
   "source": [
    "word2id = {symbol:i for i, symbol in enumerate('+-1234567890')}\n",
    "#word2id['<unk>']=11\n",
    "word2id['<pad>']=12\n",
    "word2id['$']=13\n",
    "id2word = {i:symbol for symbol, i in word2id.items()}\n",
    "print(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
    "    \n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "    \n",
    "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
    "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
    "\n",
    "    return X, np.array(Y), Xoh, Yoh\n",
    "\n",
    "def string_to_int(string, length, vocab):\n",
    "    \"\"\"\n",
    "    Converts all strings in the vocabulary into a list of integers representing the positions of the\n",
    "    input string's characters in the \"vocab\"\n",
    "    \n",
    "    Arguments:\n",
    "    string -- input string, e.g. 'Wed 10 Jul 2007'\n",
    "    length -- the number of time steps you'd like, determines if the output will be padded or cut\n",
    "    vocab -- vocabulary, dictionary used to index every character of your \"string\"\n",
    "    \n",
    "    Returns:\n",
    "    rep -- list of integers (or '<unk>') (size = length) representing the position of the string's character in the vocabulary\n",
    "    \"\"\"\n",
    "    \n",
    "    #make lower to standardize\n",
    "    string = string.lower()\n",
    "    string = string.replace(',','')\n",
    "    \n",
    "    if len(string) > length:\n",
    "        string = string[:length]\n",
    "        \n",
    "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
    "    \n",
    "    if len(string) < length:\n",
    "        rep += [vocab['<pad>']] * (length - len(string))\n",
    "    \n",
    "    #print (rep)\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "Tx = 8\n",
    "Ty = 5\n",
    "X, Y, Xoh, Yoh = preprocess_data(train_set, word2id, word2id, Tx, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 254+16$\n",
      "Target date: 270$\n",
      "\n",
      "Source after preprocessing (indices): [ 3  6  5  0  2  7 13 12]\n",
      "Target after preprocessing (indices): [ 3  8 11 13 12]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "print(\"Source date:\", train_set[index][0])\n",
    "print(\"Target date:\", train_set[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply,LSTMCell,RNN,BatchNormalization\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Reshape,TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 60\n",
    "n_s = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Builds and returns the model based on the global config.\n",
    "    \"\"\"\n",
    "    input_shape = (Tx, len(word2id))\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Encoder:\n",
    "    model.add(Bidirectional(LSTM(n_a), input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # The RepeatVector-layer repeats the input n times\n",
    "    model.add(RepeatVector(Ty))\n",
    "\n",
    "    # Decoder:\n",
    "    model.add(Bidirectional(LSTM(n_s, return_sequences=True)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(TimeDistributed(Dense(len(word2id))))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(lr=0.01),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 120)               36000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 5, 120)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 5, 2048)           9379840   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 2048)           8192      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 14)             28686     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5, 14)             0         \n",
      "=================================================================\n",
      "Total params: 9,453,198\n",
      "Trainable params: 9,448,862\n",
      "Non-trainable params: 4,336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (â‰ˆ2 lines)\n",
    "opt = Adam(lr=0.001,beta_1=0.9,beta_2=0.999,decay=0.01)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 25600 samples, validate on 6400 samples\n",
      "Epoch 1/120\n",
      "25600/25600 [==============================] - 16s 638us/step - loss: 2.0864 - acc: 0.4200 - val_loss: 1.6234 - val_acc: 0.4510\n",
      "Epoch 2/120\n",
      "25600/25600 [==============================] - 10s 376us/step - loss: 1.3027 - acc: 0.5301 - val_loss: 1.6113 - val_acc: 0.4826\n",
      "Epoch 3/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 1.1706 - acc: 0.5687 - val_loss: 1.2306 - val_acc: 0.5548\n",
      "Epoch 4/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 1.0275 - acc: 0.6133 - val_loss: 1.0231 - val_acc: 0.6184\n",
      "Epoch 5/120\n",
      "25600/25600 [==============================] - 10s 376us/step - loss: 0.8905 - acc: 0.6578 - val_loss: 0.9461 - val_acc: 0.6332\n",
      "Epoch 6/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.7848 - acc: 0.6938 - val_loss: 0.8024 - val_acc: 0.6905\n",
      "Epoch 7/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.7002 - acc: 0.7237 - val_loss: 0.7177 - val_acc: 0.7179\n",
      "Epoch 8/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.6357 - acc: 0.7470 - val_loss: 0.6539 - val_acc: 0.7431\n",
      "Epoch 9/120\n",
      "25600/25600 [==============================] - 10s 407us/step - loss: 0.5945 - acc: 0.7638 - val_loss: 0.7183 - val_acc: 0.7264\n",
      "Epoch 10/120\n",
      "25600/25600 [==============================] - 10s 378us/step - loss: 0.5397 - acc: 0.7849 - val_loss: 0.5660 - val_acc: 0.7740\n",
      "Epoch 11/120\n",
      "25600/25600 [==============================] - 10s 376us/step - loss: 0.4883 - acc: 0.8033 - val_loss: 0.5745 - val_acc: 0.7705\n",
      "Epoch 12/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.4620 - acc: 0.8158 - val_loss: 0.4971 - val_acc: 0.8076\n",
      "Epoch 13/120\n",
      "25600/25600 [==============================] - 10s 377us/step - loss: 0.4320 - acc: 0.8293 - val_loss: 0.4884 - val_acc: 0.8137\n",
      "Epoch 14/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.4063 - acc: 0.8386 - val_loss: 0.4556 - val_acc: 0.8208\n",
      "Epoch 15/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.3748 - acc: 0.8521 - val_loss: 0.4273 - val_acc: 0.8393\n",
      "Epoch 16/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.3485 - acc: 0.8636 - val_loss: 0.4018 - val_acc: 0.8458\n",
      "Epoch 17/120\n",
      "25600/25600 [==============================] - 10s 398us/step - loss: 0.3507 - acc: 0.8636 - val_loss: 0.3865 - val_acc: 0.8543\n",
      "Epoch 18/120\n",
      "25600/25600 [==============================] - 10s 388us/step - loss: 0.3183 - acc: 0.8769 - val_loss: 0.3587 - val_acc: 0.8673\n",
      "Epoch 19/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.3040 - acc: 0.8833 - val_loss: 0.3395 - val_acc: 0.8716\n",
      "Epoch 20/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.2886 - acc: 0.8902 - val_loss: 0.3332 - val_acc: 0.8793\n",
      "Epoch 21/120\n",
      "25600/25600 [==============================] - 10s 373us/step - loss: 0.2642 - acc: 0.8993 - val_loss: 0.4154 - val_acc: 0.8500\n",
      "Epoch 22/120\n",
      "25600/25600 [==============================] - 10s 395us/step - loss: 0.2523 - acc: 0.9059 - val_loss: 0.3138 - val_acc: 0.8920\n",
      "Epoch 23/120\n",
      "25600/25600 [==============================] - 10s 376us/step - loss: 0.2423 - acc: 0.9091 - val_loss: 0.3543 - val_acc: 0.8718\n",
      "Epoch 24/120\n",
      "25600/25600 [==============================] - 10s 377us/step - loss: 0.2398 - acc: 0.9116 - val_loss: 0.3032 - val_acc: 0.8970\n",
      "Epoch 25/120\n",
      "25600/25600 [==============================] - 10s 393us/step - loss: 0.2248 - acc: 0.9165 - val_loss: 0.2797 - val_acc: 0.9011\n",
      "Epoch 26/120\n",
      "25600/25600 [==============================] - 10s 396us/step - loss: 0.2261 - acc: 0.9158 - val_loss: 0.3439 - val_acc: 0.8847\n",
      "Epoch 27/120\n",
      "25600/25600 [==============================] - 10s 376us/step - loss: 0.2076 - acc: 0.9229 - val_loss: 0.2724 - val_acc: 0.9037\n",
      "Epoch 28/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1884 - acc: 0.9310 - val_loss: 0.2809 - val_acc: 0.9038\n",
      "Epoch 29/120\n",
      "25600/25600 [==============================] - 10s 373us/step - loss: 0.1997 - acc: 0.9275 - val_loss: 0.2976 - val_acc: 0.8970\n",
      "Epoch 30/120\n",
      "25600/25600 [==============================] - 11s 422us/step - loss: 0.1863 - acc: 0.9329 - val_loss: 0.3177 - val_acc: 0.8956\n",
      "Epoch 31/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1806 - acc: 0.9340 - val_loss: 0.2454 - val_acc: 0.9177\n",
      "Epoch 32/120\n",
      "25600/25600 [==============================] - 10s 380us/step - loss: 0.1740 - acc: 0.9375 - val_loss: 0.2550 - val_acc: 0.9157\n",
      "Epoch 33/120\n",
      "25600/25600 [==============================] - 10s 386us/step - loss: 0.1706 - acc: 0.9384 - val_loss: 0.2430 - val_acc: 0.9196\n",
      "Epoch 34/120\n",
      "25600/25600 [==============================] - 10s 397us/step - loss: 0.1670 - acc: 0.9401 - val_loss: 0.2318 - val_acc: 0.9222\n",
      "Epoch 35/120\n",
      "25600/25600 [==============================] - 10s 376us/step - loss: 0.1634 - acc: 0.9418 - val_loss: 0.2402 - val_acc: 0.9208\n",
      "Epoch 36/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1478 - acc: 0.9475 - val_loss: 0.2600 - val_acc: 0.9169\n",
      "Epoch 37/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1538 - acc: 0.9450 - val_loss: 0.2788 - val_acc: 0.9104\n",
      "Epoch 38/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1513 - acc: 0.9460 - val_loss: 0.2227 - val_acc: 0.9294\n",
      "Epoch 39/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.1452 - acc: 0.9485 - val_loss: 0.2724 - val_acc: 0.9146\n",
      "Epoch 40/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1485 - acc: 0.9478 - val_loss: 0.2216 - val_acc: 0.9318\n",
      "Epoch 41/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.1305 - acc: 0.9545 - val_loss: 0.2177 - val_acc: 0.9322\n",
      "Epoch 42/120\n",
      "25600/25600 [==============================] - 11s 410us/step - loss: 0.1396 - acc: 0.9518 - val_loss: 0.2779 - val_acc: 0.9180\n",
      "Epoch 43/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1394 - acc: 0.9513 - val_loss: 0.1905 - val_acc: 0.9392\n",
      "Epoch 44/120\n",
      "25600/25600 [==============================] - 10s 377us/step - loss: 0.1372 - acc: 0.9523 - val_loss: 0.1985 - val_acc: 0.9359\n",
      "Epoch 45/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1274 - acc: 0.9553 - val_loss: 0.2089 - val_acc: 0.9360\n",
      "Epoch 46/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.1325 - acc: 0.9538 - val_loss: 0.2030 - val_acc: 0.9378\n",
      "Epoch 47/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1230 - acc: 0.9578 - val_loss: 0.2051 - val_acc: 0.9351\n",
      "Epoch 48/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1260 - acc: 0.9571 - val_loss: 0.1917 - val_acc: 0.9411\n",
      "Epoch 49/120\n",
      "25600/25600 [==============================] - 10s 376us/step - loss: 0.1257 - acc: 0.9563 - val_loss: 0.2140 - val_acc: 0.9376\n",
      "Epoch 50/120\n",
      "25600/25600 [==============================] - 10s 402us/step - loss: 0.1192 - acc: 0.9590 - val_loss: 0.1940 - val_acc: 0.9390\n",
      "Epoch 51/120\n",
      "25600/25600 [==============================] - 10s 383us/step - loss: 0.1105 - acc: 0.9613 - val_loss: 0.1596 - val_acc: 0.9520\n",
      "Epoch 52/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.1119 - acc: 0.9625 - val_loss: 0.1797 - val_acc: 0.9465\n",
      "Epoch 53/120\n",
      "25600/25600 [==============================] - 10s 396us/step - loss: 0.1224 - acc: 0.9588 - val_loss: 0.2162 - val_acc: 0.9353\n",
      "Epoch 54/120\n",
      "25600/25600 [==============================] - 10s 377us/step - loss: 0.1275 - acc: 0.9571 - val_loss: 0.1930 - val_acc: 0.9422\n",
      "Epoch 55/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.1160 - acc: 0.9606 - val_loss: 0.1788 - val_acc: 0.9472\n",
      "Epoch 56/120\n",
      "25600/25600 [==============================] - 10s 375us/step - loss: 0.1064 - acc: 0.9643 - val_loss: 0.1934 - val_acc: 0.9428\n",
      "Epoch 57/120\n",
      "25600/25600 [==============================] - 10s 374us/step - loss: 0.1050 - acc: 0.9643 - val_loss: 0.1799 - val_acc: 0.9493\n",
      "Epoch 58/120\n",
      "18816/25600 [=====================>........] - ETA: 2s - loss: 0.1214 - acc: 0.9600"
     ]
    }
   ],
   "source": [
    "#model.load_weights('../input/my_model_weights.h5', by_name=True)\n",
    "model.fit(Xoh,Yoh, epochs=120, batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_index(vector):\n",
    "    if not np.any(vector):\n",
    "        return -1\n",
    "\n",
    "    return np.argmax(vector)\n",
    "\n",
    "def one_hot_to_char(vector):\n",
    "    index = one_hot_to_index(vector)\n",
    "    if index == -1:\n",
    "        return ''\n",
    "\n",
    "    return id2word[index]\n",
    "\n",
    "def one_hot_to_string(matrix):\n",
    "    return ''.join(one_hot_to_char(vector) for vector in matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "source: 655-751$\n",
      "real: -96$\n",
      "output: -96$<pad>\n",
      "##########\n",
      "source: 573+671$\n",
      "real: 1244$\n",
      "output: 1244$\n",
      "##########\n",
      "source: 3+849$\n",
      "real: 852$\n",
      "output: 852$<pad>\n",
      "##########\n",
      "source: 254+16$\n",
      "real: 270$\n",
      "output: 270$<pad>\n",
      "##########\n",
      "source: 61+419$\n",
      "real: 480$\n",
      "output: 470$<pad>\n",
      "##########\n",
      "source: 307+731$\n",
      "real: 1038$\n",
      "output: 1038$\n",
      "##########\n",
      "source: 930+790$\n",
      "real: 1720$\n",
      "output: 1720$\n",
      "##########\n",
      "source: 866-317$\n",
      "real: 549$\n",
      "output: 549$<pad>\n",
      "##########\n",
      "source: 485-266$\n",
      "real: 219$\n",
      "output: 219$<pad>\n",
      "##########\n",
      "source: 452-81$\n",
      "real: 371$\n",
      "output: 371$<pad>\n",
      "##########\n",
      "source: 659-86$\n",
      "real: 573$\n",
      "output: 573$<pad>\n",
      "##########\n",
      "source: 772+541$\n",
      "real: 1313$\n",
      "output: 1313$\n",
      "##########\n",
      "source: 28-436$\n",
      "real: -408$\n",
      "output: -408$\n",
      "##########\n",
      "source: 265-135$\n",
      "real: 130$\n",
      "output: 130$<pad>\n",
      "##########\n",
      "source: 698-491$\n",
      "real: 207$\n",
      "output: 207$<pad>\n",
      "##########\n",
      "source: 997-198$\n",
      "real: 799$\n",
      "output: 799$<pad>\n",
      "##########\n",
      "source: 967+232$\n",
      "real: 1199$\n",
      "output: 1199$\n",
      "##########\n",
      "source: 829+957$\n",
      "real: 1786$\n",
      "output: 1786$\n",
      "##########\n",
      "source: 321-480$\n",
      "real: -159$\n",
      "output: -159$\n",
      "##########\n",
      "source: 910-994$\n",
      "real: -84$\n",
      "output: -84$<pad>\n",
      "##########\n",
      "source: 317+959$\n",
      "real: 1276$\n",
      "output: 1276$\n",
      "##########\n",
      "source: 89-30$\n",
      "real: 59$\n",
      "output: 59$<pad><pad>\n",
      "##########\n",
      "source: 503+245$\n",
      "real: 748$\n",
      "output: 748$<pad>\n",
      "##########\n",
      "source: 513+604$\n",
      "real: 1117$\n",
      "output: 1117$\n",
      "##########\n",
      "source: 808-86$\n",
      "real: 722$\n",
      "output: 722$<pad>\n",
      "##########\n",
      "source: 408+524$\n",
      "real: 932$\n",
      "output: 93$2<pad>\n",
      "##########\n",
      "source: 528-65$\n",
      "real: 463$\n",
      "output: 463$<pad>\n",
      "##########\n",
      "source: 584-883$\n",
      "real: -299$\n",
      "output: -299$\n",
      "##########\n",
      "source: 888+979$\n",
      "real: 1867$\n",
      "output: 1867$\n",
      "##########\n",
      "source: 903+588$\n",
      "real: 1491$\n",
      "output: 1491$\n",
      "##########\n",
      "source: 903-624$\n",
      "real: 279$\n",
      "output: 289$<pad>\n",
      "##########\n",
      "source: 562-394$\n",
      "real: 168$\n",
      "output: 168$<pad>\n",
      "##########\n",
      "source: 97+590$\n",
      "real: 687$\n",
      "output: 687$<pad>\n",
      "##########\n",
      "source: 550-330$\n",
      "real: 220$\n",
      "output: 220$<pad>\n",
      "##########\n",
      "source: 597+320$\n",
      "real: 917$\n",
      "output: 907$<pad>\n",
      "##########\n",
      "source: 445+541$\n",
      "real: 986$\n",
      "output: 986$<pad>\n",
      "##########\n",
      "source: 924+69$\n",
      "real: 993$\n",
      "output: 993$<pad>\n",
      "##########\n",
      "source: 891+883$\n",
      "real: 1774$\n",
      "output: 1774$\n",
      "##########\n",
      "source: 329-166$\n",
      "real: 163$\n",
      "output: 163$<pad>\n",
      "##########\n",
      "source: 333+293$\n",
      "real: 626$\n",
      "output: 626$<pad>\n",
      "##########\n",
      "source: 366+549$\n",
      "real: 915$\n",
      "output: 915$<pad>\n",
      "##########\n",
      "source: 377-253$\n",
      "real: 124$\n",
      "output: 124$<pad>\n",
      "##########\n",
      "source: 563-543$\n",
      "real: 20$\n",
      "output: 10$<pad><pad>\n",
      "##########\n",
      "source: 103+502$\n",
      "real: 605$\n",
      "output: 605$<pad>\n",
      "##########\n",
      "source: 388-356$\n",
      "real: 32$\n",
      "output: 32$<pad><pad>\n",
      "##########\n",
      "source: 902+440$\n",
      "real: 1342$\n",
      "output: 1342$\n",
      "##########\n",
      "source: 54+515$\n",
      "real: 569$\n",
      "output: 569$<pad>\n",
      "##########\n",
      "source: 897+245$\n",
      "real: 1142$\n",
      "output: 1142$\n",
      "##########\n",
      "source: 787-754$\n",
      "real: 33$\n",
      "output: 33$<pad><pad>\n",
      "##########\n",
      "source: 585-144$\n",
      "real: 441$\n",
      "output: 441$<pad>\n",
      "##########\n",
      "source: 765-540$\n",
      "real: 225$\n",
      "output: 225$<pad>\n",
      "##########\n",
      "source: 178-377$\n",
      "real: -199$\n",
      "output: -299$\n",
      "##########\n",
      "source: 419-950$\n",
      "real: -531$\n",
      "output: -531$\n",
      "##########\n",
      "source: 113+963$\n",
      "real: 1076$\n",
      "output: 1076$\n",
      "##########\n",
      "source: 337-693$\n",
      "real: -356$\n",
      "output: -356$\n",
      "##########\n",
      "source: 906+913$\n",
      "real: 1819$\n",
      "output: 1819$\n",
      "##########\n",
      "source: 528-662$\n",
      "real: -134$\n",
      "output: -134$\n",
      "##########\n",
      "source: 396-154$\n",
      "real: 242$\n",
      "output: 242$<pad>\n",
      "##########\n",
      "source: 258+747$\n",
      "real: 1005$\n",
      "output: 1005$\n",
      "##########\n",
      "source: 877-902$\n",
      "real: -25$\n",
      "output: -25$<pad>\n",
      "##########\n",
      "source: 157+967$\n",
      "real: 1124$\n",
      "output: 1124$\n",
      "##########\n",
      "source: 218-558$\n",
      "real: -340$\n",
      "output: -340$\n",
      "##########\n",
      "source: 824-325$\n",
      "real: 499$\n",
      "output: 499$<pad>\n",
      "##########\n",
      "source: 743-293$\n",
      "real: 450$\n",
      "output: 440$<pad>\n",
      "##########\n",
      "source: 391+20$\n",
      "real: 411$\n",
      "output: 401$<pad>\n",
      "##########\n",
      "source: 594-797$\n",
      "real: -203$\n",
      "output: -203$\n",
      "##########\n",
      "source: 679+2$\n",
      "real: 681$\n",
      "output: 681$<pad>\n",
      "##########\n",
      "source: 243-614$\n",
      "real: -371$\n",
      "output: -371$\n",
      "##########\n",
      "source: 757+325$\n",
      "real: 1082$\n",
      "output: 1082$\n",
      "##########\n",
      "source: 894+543$\n",
      "real: 1437$\n",
      "output: 1437$\n",
      "##########\n",
      "source: 840+521$\n",
      "real: 1361$\n",
      "output: 1361$\n",
      "##########\n",
      "source: 654-774$\n",
      "real: -120$\n",
      "output: -120$\n",
      "##########\n",
      "source: 726-842$\n",
      "real: -116$\n",
      "output: -116$\n",
      "##########\n",
      "source: 757+789$\n",
      "real: 1546$\n",
      "output: 1546$\n",
      "##########\n",
      "source: 656+379$\n",
      "real: 1035$\n",
      "output: 1035$\n",
      "##########\n",
      "source: 360-47$\n",
      "real: 313$\n",
      "output: 313$<pad>\n",
      "##########\n",
      "source: 453-447$\n",
      "real: 6$\n",
      "output: 6$<pad><pad><pad>\n",
      "##########\n",
      "source: 811+116$\n",
      "real: 927$\n",
      "output: 927$<pad>\n",
      "##########\n",
      "source: 693+980$\n",
      "real: 1673$\n",
      "output: 1673$\n",
      "##########\n",
      "source: 409-324$\n",
      "real: 85$\n",
      "output: 85$<pad><pad>\n",
      "##########\n",
      "source: 428-939$\n",
      "real: -511$\n",
      "output: -511$\n",
      "##########\n",
      "source: 531-196$\n",
      "real: 335$\n",
      "output: 335$<pad>\n",
      "##########\n",
      "source: 229+867$\n",
      "real: 1096$\n",
      "output: 1096$\n",
      "##########\n",
      "source: 11+46$\n",
      "real: 57$\n",
      "output: 57$<pad><pad>\n",
      "##########\n",
      "source: 660+333$\n",
      "real: 993$\n",
      "output: 993$<pad>\n",
      "##########\n",
      "source: 32+8$\n",
      "real: 40$\n",
      "output: 49$<pad><pad>\n",
      "##########\n",
      "source: 300-913$\n",
      "real: -613$\n",
      "output: -613$\n",
      "##########\n",
      "source: 207-882$\n",
      "real: -675$\n",
      "output: -675$\n",
      "##########\n",
      "source: 149-379$\n",
      "real: -230$\n",
      "output: -230$\n",
      "##########\n",
      "source: 460-919$\n",
      "real: -459$\n",
      "output: -459$\n",
      "##########\n",
      "source: 456+846$\n",
      "real: 1302$\n",
      "output: 1302$\n",
      "##########\n",
      "source: 304-295$\n",
      "real: 9$\n",
      "output: 9$<pad><pad><pad>\n",
      "##########\n",
      "source: 32+627$\n",
      "real: 659$\n",
      "output: 659$<pad>\n",
      "##########\n",
      "source: 866+777$\n",
      "real: 1643$\n",
      "output: 1643$\n",
      "##########\n",
      "source: 383+948$\n",
      "real: 1331$\n",
      "output: 1331$\n",
      "##########\n",
      "source: 847+833$\n",
      "real: 1680$\n",
      "output: 1680$\n",
      "##########\n",
      "source: 949+251$\n",
      "real: 1200$\n",
      "output: 1200$\n",
      "##########\n",
      "source: 443+219$\n",
      "real: 662$\n",
      "output: 662$<pad>\n",
      "##########\n",
      "source: 544-612$\n",
      "real: -68$\n",
      "output: -68$<pad>\n",
      "##########\n",
      "source: 457-575$\n",
      "real: -118$\n",
      "output: -118$\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = [i for i in train_set[0:100]]\n",
    "for example,real in EXAMPLES:\n",
    "    #print(example)\n",
    "    source = string_to_int(example, Tx, word2id)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(word2id)), source))).swapaxes(0,1)\n",
    "    source=np.transpose(source)\n",
    "    source=source.reshape(1,Tx,len(word2id))\n",
    "    \n",
    "    result=model.predict(source)\n",
    "    result=result.reshape(Ty,len(word2id))\n",
    "    #real = string_to_int(real, Ty, word2id)\n",
    "    #real = np.array(list(map(lambda x: to_categorical(x, num_classes=len(word2id)), real))).swapaxes(0,1)\n",
    "    #real=real.reshape(1,Tx,len(word2id))\n",
    "    #print(result)\n",
    "    #print(real)\n",
    "    result=one_hot_to_string(result)\n",
    "    print('##########')\n",
    "    print(\"source:\", example)\n",
    "    print('real:',real)\n",
    "    print(\"output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 17s 528us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05774638700159267, 0.9829374976754188]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xoh,Yoh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 4s 525us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11648644245229661, 0.9697000007629395]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt, Yt, Xoht, Yoht = preprocess_data(test_set, word2id, word2id, Tx, Ty)\n",
    "model.evaluate(Xoht, Yoht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
